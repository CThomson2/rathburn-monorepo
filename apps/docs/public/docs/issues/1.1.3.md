# Production Scheduling Cross-App Feature Development

## v1.1.3

### Mobile App

- [x] Add a "Free Scan" option for new scanning sessions where users can scan any barcode without it being associated with a task (mainly used for real-life debugging)
- [x] Use caching to prevent frequent re-loading of the task selection modal on open and close
- [x] Show the completed sessions on reloading of page. Whenever a reload occurs, fetch data from the database for up-to-date scan session progress
- [x] Remove the tasks that are already completed from the task selection modal `task-selection-modal.tsx`
- [x] Completed Sessions now do not show up on the Task Selection menu anymore
- [x] Task progress persists across sessions
- [x] Buttons for task selection, cancellation etc. are now always in view regardless of screen size
- [x] Error in simulataneous scanning sessions across multiple devices has been fixed - we can now use the same account on two devices without syncing issues
- [x] In Free Scan mode, make the Gauge Counter increment by 1 for each scan, and show the scans in the `session-report.tsx` component

### Database

- [ ] Audit existing data in the `inventory` schema to ensure that the `drums` table is up to date with the latest changes. _Enhanced trigger logic and relational functionality was added after hundreds of rows had already been inserted into some tables without the new logic propagating to other tables_.
  - Write queries to check and relate all `status` field values across the connected `inventory` schema tables.
  - Remove any drum/order records which were created, but since then the drum has been moved into processing without the new system being updated.
  - Check that the `purchase_orders` status is being correctly updated based on the `purchase_order_lines` trigger logic.
  - Review columns in `inventory` tables, e.g. `batch`, `drums` etc. to ensure that the appropriate columns exist in each table.
    - The `drums` table needs a more direct link to originating purchase order lines
    - Currently there may be an over-use of normalisation
- [x] Debug and fix the `batches` table, as it is not being updated correctly with the new trigger functions
  - The `create_pending_drum_for_po_drum` trigger function is not working as expected.
- [ ] Review schema organisation for confidence that the tables and functions are in the appropriate schemas
- [ ] Review the need for the `config` schema - could these tables just be in `public` instead?
- [ ] There is likely a large degree of duplication in the functions - can we consolidate them?
  - Review the disabled trigger functions, as they may be deprecated
  - Ensure that naming conventions are consistent and understandable
- [ ] Review existing views, as some may be redundant or could be improved
- [ ] Create a concrete set of RLS policies after adding new user accounts for employees
- [ ] Perform end-to-end testing of the new functionality in the mobile app, database and data fetching/realtime in web app (and vice versa for tasks posted by web app client)

### Web App

- [ ] Find instances of UUIDs being displayed in views, and replace them for meaningful information
  - Location ID in the drum detail panel
  - Batch ID in batches inventory view

```sql
CREATE OR REPLACE FUNCTION inventory.create_pending_drum_for_po_drum()
RETURNS TRIGGER AS $$
DECLARE
  v_batch_id uuid;
  v_item_id uuid;
  v_pol_id uuid := NEW.pol_id;
  v_po_id uuid;
  v_batch_volume numeric;
BEGIN
  -- 1. Get the item_id and po_id from the purchase_order_lines table
  SELECT po_id, item_id INTO v_po_id, v_item_id
  FROM inventory.purchase_order_lines
  WHERE pol_id = v_pol_id;

  -- 2. Find or create a batch associated with the item_id and po_id
  -- This logic might need adjustment based on how batches are uniquely identified.
  -- Assuming a batch is uniquely identified by item_id and po_id for incoming goods.
  SELECT batch_id, total_volume INTO v_batch_id, v_batch_volume
  FROM inventory.batches
  WHERE item_id = v_item_id AND po_id = v_po_id
  LIMIT 1;

  IF v_batch_id IS NOT NULL then
    UPDATE inventory.batches
    SET total_volume = v_batch_volume + 1
    WHERE batch_id = v_batch_id AND po_id = v_po_id;
  ELSE
    INSERT INTO inventory.batches (item_id, po_id, batch_type, total_volume)
    VALUES (v_item_id, v_po_id, 'new', 1)
    RETURNING batch_id INTO v_batch_id;
  END IF;

  -- 3. Insert into inventory.drums
  INSERT INTO inventory.drums (batch_id, serial_number, status, current_volume, created_at, updated_at)
  VALUES (
    v_batch_id,
    NEW.serial_number,
    'pending', -- Initial status
    200, -- Initial volume, adjust if known
    NOW(),
    NOW()
  )
  RETURNING drum_id INTO NEW.drum_id; -- Attempt to update the triggering row's drum_id

  RETURN NEW;
EXCEPTION
  WHEN unique_violation THEN
    -- Handle cases where a drum with this serial number might already exist (e.g., trigger ran twice)
    RAISE NOTICE 'Drum with serial number % already exists. Skipping insertion.', NEW.serial_number;
    -- Optionally, find the existing drum_id and update NEW.drum_id
    SELECT drum_id INTO NEW.drum_id
    FROM inventory.drums
    WHERE serial_number = NEW.serial_number;
    RETURN NEW;
  WHEN OTHERS THEN
    -- Log other errors
    RAISE WARNING 'Error in create_pending_drum_for_po_drum trigger for pod_id %: %', NEW.pod_id, SQLERRM;
    RETURN NEW; -- Allow the original insert to proceed even if drum creation fails?
END;
LANGUAGE plpgsql;
$$;
```
